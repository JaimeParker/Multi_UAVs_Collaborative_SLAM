# 开题报告

一、选题背景、意义及依据

二、国内外研究现状

三、课题研究目标、研究内容、研究方法及关键技术

四、论文所遇到的困难和问题、拟采取的解决措施及预期达到的目标

五、论文进度安排

六、参考文献

## 一、选题背景、意义及依据

基于UWB的集群无人机协同定位与建图；

选题有三个方面的考量，==集群协作，定位建图==；因此从三个方面分别介绍选题的背景和意义；





当今阶段，==无人机==技术迅速发展，在单架无人机上可以集成更多的系统，意味着对于单机更强大的功能。但是，面对复杂的应用环境和多样化的需求，单架无人机受自身软硬件条件的限制，仍然具有一些局限性；为了弥补单架无人机的局限性，由多架相同或不同型号的无人机组成多无人机系统，协同定位，共同完成任务；

> 单薄

通过==集群==的方式，能最大地发挥无人机的优势，又能避免由于单架无人机执行任务不佳或失败造成的不良后果，提高任务执行效率，扩展新的任务执行方式，从而达到提高系统可靠性，该神任务执行效果的目的。

> 引出问题，引出要做的工作；
>
> 好处+问题





扩展





==定位与建图==技术已经有三十多年的研究，主要方法是SLAM（simultaneous localization and mapping），即同时定位与建图；SLAM 最早由 Smith、Self 和 Cheeseman 于 1988年提出。由于其重要的理论与应用价值，被很多学者认为是实现真正全自主移动机器人的关键。

对于无人机的自主导航，能够在进入提前未知的环境时掌握无人机的位置和姿态是使其成功的关键。尽管GPS对于掌握无人机的位置有巨大的帮助，但仍存在普适性有限和准确度不高的问题；在一些特定场景下，比如室内狭小空间，对定位精度要求很高，GPS定位的局限性就被显露出来。而SLAM技术则可以仅通过自身携带的传感器，来完成这一任务，同时达到一定的精度；

> Distributed Variable-Baseline Stereo SLAM from two UAVs, [abstract website](https://ieeexplore.ieee.org/abstract/document/9560944)





> 意义及依据，难题引出





==UWB==（Ultra Wide Band）技术是一种无线载波通信技术，它不采用正弦载波，而是利用纳秒级的非正弦波窄脉冲传输数据，因此其所占的频谱范围很宽。具有系统复杂度低，发射信号功率谱密度低，对信道衰落不敏感，截获能力低，定位精度高等优点，尤其适用于室内等密集多径场所的高速无线接入，与SLAM的应用场景也比较契合。

> 熊茂华，熊昕编著．物联网技术与应用开发[M]．西安：西安电子科技大学出版社，2012.08

## 二、国内外研究现状

学长的题是协同环境感知与控制，然后研究现状写了SLAM的四个方向和机器人控制的内容，相当于总共两部分；

因此我这个方向SLAM不得不提，另外就是无人机+SLAM的研究都有哪些成果；要先说SLAM，再加上无人机，最后提集群；

[无人机视觉SLAM协同建图与导航](http://xb.sinomaps.com/article/2020/1001-1595/2020-6-767.htm)

### 2.1 SLAM

==同时定位与建图（SLAM）==技术在国内外机器人、无人驾驶等领域趋于成熟。SLAM主要分为视觉SLAM、激光SLAM、融合SLAM和新颖SLAM。

对于==视觉SLAM==，即用相机完成同时定位与建图的任务。由于相机造价相对较低、电量消耗相对较少、能够获取环境的大量信息，因此相机成为了完成定位与建图任务常用的传感器。视觉SLAM主要有五个步骤，传感器信息读取、视觉里程计（Visual Odometry）、后端优化（Optimization）、回环检测（Loop Closing）、建图（Mapping）。对于静态、刚体、光照变化不明显、且没有过多人为干扰的场景，视觉SLAM技术已经十分成熟。当前比较好的方案有`ORB-SLAM`；其在对特征点的描述上做了很大创新，相比于SIFT（尺度不变特征变换，Scale-invariant feature transform）的大计算量和对GPU的特殊需求、FAST关键点描述没有描述子的缺点，`ORB`改进了FAST的检测子，为其增加了方向性，并且采用了二进制描述子BRIEF（Binary Robust Independent Elementary Feature）。

> [高翔, 张涛, 颜沁睿, 刘毅, 视觉SLAM十四讲：从理论到实践, 电子工业出版社, 2017](https://github.com/gaoxiang12/slambook#slambook-%E4%B8%AD%E6%96%87%E8%AF%B4%E6%98%8E)
>
> [ORB: An efficient alternative to SIFT or SURF](https://ieeexplore.ieee.org/abstract/document/6126544)

*视觉SLAM是？特点？分类？*

对于==激光SLAM==，主要有两种传感器，单线束激光雷达和多线束激光雷达；单线束激光雷达即2D雷达，2D激光雷达的扫描范围比较单一，角度有限，因此比较适合仅平面运动的机器人的定位与建图，对应的经典算法如`GMapping`；多线束雷达即3D雷达，其获取的信息包含距离和角度，能够还原出目标的三维点云，且不受光照影响，缺点是造价比较昂贵且易受不良天气影响，对应的经典算法如谷歌提出的`Cartographer`。

> 单线束激光雷达-[基于激光雷达的移动机器人环境建模与避障](https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFD2000&filename=QHXB200007029&uniplatform=NZKPT&v=AgAWxaL2JlkBj0T3uz7aOjUzD18oAq8EGA_si6UlgqqFm3tGqZBJhMMqx4-FLSXT)

对于==融合SLAM==，常见的有视觉和惯性的融合，即相机+IMU（inertial measurement unit，惯性测量单元，包含加速度计和角加速度计）等的多传感器融合；IMU的工作原理是对加速度的积分、初始速度和起始位置进行混合运算，得到运动轨迹和位姿。但是其容易产生漂移（Drift），并且这种累积误差会随时间增加。

> IMU的累积误差-[Calibration of an Inertial Measurement Unit](https://link.springer.com/article/10.1007/s10778-017-0808-4)

对于==VIO（视觉惯性里程计）==，即上文提到的由相机和惯性测量单元组成的融合传感器，根据融合的框架可以分为松耦合和紧耦合两种。松耦合中对相机关键帧数据的视觉运动估计和对IMU测量数据的运动估计是两个独立的模块，计算时互不干涉；计算完成后将其轨迹结果按一定的方法进行融合。紧耦合则是共同使用相机视觉数据和惯导运动估计数据，共同完成对一组变量的估计；因此其算法更加复杂，且传感器之间的噪声也会相互影响，但是具有更好的效果，也是目前阶段研究的重点方向。这方向上好的方案有`VINS-fusion`。

> [VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator](https://ieeexplore.ieee.org/abstract/document/8421746)

对于==新颖SLAM== ，比如语义SLAM；使用神经网络的语义分割、目标检测方法，从图像到位姿，使用其语义分割的结果来完成点云地图的建立和场景识别。语义SLAM能够探测出图像中的各个物体，并且能得到在图像中的位置，可以节省传统的人工标定物品的成本，方便机器人的自主理解能力和简便的人机交互。

> [移动机器人同步定位与建图技术综述](https://kns-cnki-net-443.webvpn.nwpu.edu.cn/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDAUTO&filename=JZCK202202001&uniplatform=NZKPT&v=5Im9jGA2j6YRvNp5n2MfVPckL4joBRKv-coYxovzjkw2hU5kvBcIEOVM17AJ7Dej)

### 2.2 无人机的SLAM（改名）

无人机平台的SLAM





而在无人机上配备SLAM技术进行定位与建图已经发展地十分完善。以四旋翼无人机为例，其良好的空中悬停能力，能够传输中近距离稳定的图像传输；且无人机在空中飞行，地形和地面的障碍物对其限制较少，障碍物之间遮挡较少，能够较简单地建图。

无人机上本身配备IMU单元，是使用VIO方法进行定位与建图的可选平台。来自==苏黎世联邦理工大学的机器人视觉实验室在近期的研究==中，就涉及了多无人机协同定位与建图的内容。他们认为在场景与相机的距离较远时，比如说无人机搭载的相机的距地面较远，VIO方法的准确度会有较大下降；因为更小的夹角意味着更不准确的深度估计。因此他们在协同SLAM过程中，引入了可变基线的方法，基线的大小应该根据场景深度和任务要求的精确度来确定。

==ETH的研究==是在两架无人机上运行分布式协作SLAM，无人机之间用WIFI进行通信。系统分为三个主要部分，跟踪（tracking）、建图（mapping）、优化（optimization）。在跟踪进程中，图片数据和惯导的数据结合来完成3D地图点的定位；由扩展卡尔曼滤波方法完成信息融合，保证计算效率和低延迟；  在建图进程中，通过完成对最新的关键帧与一个从KFs选择的KF的三角测量建立3D Map Points；还需要更新地图点的不确定估计，建立现有的地图点与非原始KFs的联系；当建图进程完成对地图点的初始化之后，用非线性优化更新地图点，同时将UWB的测距信息引入到位姿估计中；在优化进程中，用ADMM算法确保两架无人机估计轨迹相同；使用基于EKF（扩展卡尔曼滤波）的位姿估计，新的地图点MP（Map Points）产生源于已有的关键帧和新产生的关键帧之间的三角测量，并且对新产生地图点的不确定性进行估计；其后端使用分布式优化，在这一部分引入了UWB，负责获得无人机之间的距离，并且在优化中完成UWB距离测量信息和视觉测量信息的融合，使多架无人机之间保持一致的估计。在无人机之间的通信方面，摒弃了大量图片信息的传输，取而代之传输关键帧的时间戳和ID信息、2D关键点的位置、关键点的描述子、跟踪的位姿等信息，这样加快了信息处理的速度。

###  2.3 多机建图的拼合（集群SLAM/多机SLAM）

关于==多机建图的拼合==问题，Christian Forster，Simon Lynen等人在研究中指出，无人机将作为分布式的预处理器，只把关键帧的特征描述和位姿估计传给地面站，地面站会给每架无人机建立单独的地图，并且在检测到重叠的时候完成对地图的拼接。其开发了自己的CSfM系统，该系统的一个基本特性就是能够判断无人机是否进入了一个其他无人机及本机已经扫描过的环境，重叠的判断主要是根据关键战的特征描述，但仍然需要进行几何验证。在外观的重叠检测时，使用了基于BRISK特征的地点识别器，之后用三点（P3P）算法进行几何验证，将P3P的结果整合到RANSAC中进行去除异常值的操作，最后完成地图合并。

> [Collaborative Monocular SLAM with Multiple Micro Aerial Vehicles](https://ieeexplore.ieee.org/document/6696923) 
>
> 加内容
>
> [CCM‐SLAM: Robust and efficient centralized collaborative monocular simultaneous localization and mapping for robotic teams - Schmuck - 2019 - Journal of Field Robotics - Wiley Online Library](https://onlinelibrary.wiley.com/doi/10.1002/rob.21854)



### 2.4 问题和发展方向（研究现状分析）

**待补充**



引出下文



## 三、课题研究目标、研究内容、研究方法及关键技术

### 3.1 研究目标（做成一个什么样的）

**一句话描述：**

完成一个xxx的目标

==以上最终实现，以下目标拆分==



> 目标!=工作内容
>
> 

仿真方面：

1. 使用gazebo模拟一个无人机、多个无人机飞行
2. 采集无人机拍摄的画面
3. 利用采集的无人机画面，使用成熟的SLAM程序，实现单机视觉SLAM定位（没有GPS）
4. 模拟UWB+单机视觉SLAM定位
5. 基于视觉协同的多机SLAM，先使用数据集实验，再用gazebo里模拟场景实验
6. 加上UWB的多机视觉SLAM协同定位与建图

真机方面：

1. 学习PX4飞行控制，能够用遥控器手动控制四旋翼无人机飞行  ==（不是目标）==
2. 使用MAVROS+QGC完成无人机的起飞、按航路点飞行、降落
3. 将模拟环境下的单机SLAM算法在真机上验证

SLAM方面：



**不分细，三个点**



本研究旨在实现一套能够在室内高精度环境或GPS拒止环境下使用视觉进行多机定位和大范围建图的多无人机协同SLAM的方案；其中：

l 在仿真方面：首先在gazebo中完成单机和多机的编队飞行；然后针对单机，采集其拍摄的画面，并且用成熟的SLAM程序实现单机的视觉SLAM；之后引入多机协同，找到一种地图融合的方法，先用数据集实验，再用gazebo中的场景实验；最终在ROS的gazebo中实现多机协同同时定位与建图。

l 在真机方面：首先实现MAVROS+QGC的无人机起飞、航路点飞行、降落；进而实现单机的视觉SLAM；在安全的前提下实现双机协同SLAM，将仿真环境下的协同SLAM算法在真机上完成验证，分析其建图结果。

l 在SLAM方面：掌握一些优秀的开源方案，选择各自优点做出一定的融合，并且有一套针对地图融合的方法。

### 3.2 研究内容（做哪些事）

> 仿真+真机

单独的视觉SLAM已经比较成熟，而在无人机上搭载SLAM算法进行定位与建图是国内外各大高校研究的重点；**大块工作 3**

多机协同SLAM能大大提高任务进行的效率，但同时由于无人机数量较多，协同上存在一定困难；UWB的引入可以提高定位精度。因此，本次研究内容是多机协作进行定位与建图，并且可以引入UWB提高精度。

研究内容分为两个模块：==SLAM模块和无人机协同模块==。

SLAM模块的主要内容是实现一套成熟的SLAM方案，==实现的步骤==有：

* 根据单架无人机拍摄的照片进行三维重建，即三维SLAM，根据无人机拍摄的图片进行特征点选取，特征点匹配，进行三维重建。先进行稀疏点云地图的重建。
* 由于涉及到多机，要进行各无人机建图的拼接合并，最终得到解决重叠问题的拼接三维稀疏点云地图。如果要构建稠密三位点云，则还需要深度图估计。

无人机协同模块的主要内容是控制无人机的协同飞行及通信，实现的步骤有：

* 根据SLAM和UWB的结果，完成自身定位。
* 多机的情况下，控制好无人机之间的间距（baseline），如果基线可变，则应有一个详细的算法控制基线距离。
* 完成无人机与地面站、无人机与无人机之间的通信、尤其是重要的用于SLAM的信息传递。



编队 提现，飞行控制

去掉步骤，SLAM的点，细分？，理论编程实现的事，优化方法协同数据？，仿真？；；主要和对接SLAM

### 3.3 关键技术

还是从SLAM+无人机上说：



实现研究内容需要以下关键技术：



是什么，为什么是KT？？？？？？



* SLAM技术相关内容，比如特征点的提取，对于特征点提取为基础的视觉SLAM，需要了解其内核原理，明白特征点的查找和匹配的相关原理，了解后端的优化过程等。
* 涉及视觉惯性里程计之后VIO的理论，对多传感器和计算获得的位姿的优化，点云图的生成
* ==图像重叠的判断，地图整合的算法等== ，**细化后加到四**



* 无人机的控制，在仿真过程中需要调试，在真机上需要更大量的调试。
* 无人机和地面站之间的通讯，信息的传递。
* 如果有的UWB的情况下，完成信息的融合。
* 确保无人机安全起飞，按计划飞行并安全降落。为了更好的控制，需要一个合理的控制策略来进行运动规划。



> 仿真的必要性
>
> 整合一下

### 3.4 研究方法和步骤

* 首先对参考文献进行略读和精读，略读了解文章的大致内容，查找兴趣点，决定需不需要仔细研究。对挑选出来的文章进行精读，做好翻译，建立对其研究问题的认识，了解解决问题的方法。
* 学习SLAM的基础知识，明白SLAM技术的内部原理，比如通过特征点估算运动和一些先进的后端优化方法，能够手动实现一些SLAM工程。最好找到一个开源的优秀的SLAM框架，加以理解和运用。用无人机拍摄的照片进行SLAM，并且后续生成点图。
* 学习OpenCV和多视图几何的基本知识，熟练运用OpenCV内部函数，最终完成地图的构建。
* 学习使用ROS环境，和地面站如QGC和Fast Planning的配置，明白ROS的信息通信，话题的发布和接收，学会写自己的软件包并且在catkin工程中调用。



> 细化

## 四、论文所遇到的困难和问题、拟采取的解决措施及预期达到的目标

### 4.1 困难和问题

论文中遇到的主要困难和问题主要有：

* SLAM基础的学习，对其中数学知识了解较少，编程能力不强
* 对于ROS，MAVROS，PX4的应用不熟练
* 对一些优秀的开源SLAM方法理解不深
* 真机调试能力欠缺

==能力上仅，+ 研究内容上的==

### 4.2 解决措施

* 解决措施为努力学习SLAM基础知识，学会有的放矢，抓住主要矛盾，先从整体上完成工程，再对其内部的细节和创新点进行探索、学习和研究
* 要多查官网，找寻获取信息的渠道和解决问题的方法

### 4.3 预期目标

* 在仿真中自建场景，完成多机视觉SLAM定位与建图
* 在真机上完成单机SLAM，并且在电脑上完成建图



或

### 4.4 问题4

### 4.5 问题5

> 对照一下
>
> 主要问题，技术上，基础知识上，2类

## 五、论文进度安排

2022/1/15-2021/1/31：学习SLAM算法，了解其基本原理

2022/1/31-2022/2/14：跑通无人机上的SLAM代码，能够使用无人机建图

2022/2/14-2022/2/28：详细学习OpenCV的成员函数

2022/3/1-2022/3/21：研究掌握拼接地图的策略和方法

2022/3/21-2022/4/7：研究多机SLAM，并且引入地图拼接

2022/4/7-2022/5/1：整合代码，真机实验

2022/5/1-2022/6/1：论文撰写，准备答辩

## 六、参考文献

* 王晨捷, 罗斌, 李成源, 等. 无人机视觉SLAM协同建图与导航. 测绘学报，2020，49(6)：767-776. DOI: 10.11947/j.AGCS.2020.20190145
* M. Karrer and M. Chli, "Distributed Variable-Baseline Stereo SLAM from two UAVs," 2021 IEEE International Conference on Robotics and Automation (ICRA), 2021, pp. 82-88, doi: 10.1109/ICRA48506.2021.9560944.
* 熊茂华，熊昕编著．物联网技术与应用开发[M]．西安：西安电子科技大学出版社，2012.08
* E. Rublee, V. Rabaud, K. Konolige and G. Bradski, "ORB: An efficient alternative to SIFT or SURF," 2011 International Conference on Computer Vision, 2011, pp. 2564-2571, doi: 10.1109/ICCV.2011.6126544.
* 高翔, 张涛, 颜沁睿, 刘毅, 视觉SLAM十四讲：从理论到实践, 电子工业出版社, 2017
* 杨明,王宏,何克忠,张钹.基于激光雷达的移动机器人环境建模与避障[J].清华大学学报(自然科学版),2000(07):112-116.DOI:10.16511/j.cnki.qhdxxb.2000.07.030.
* Avrutov, V.V., Sapegin, A.N., Stefanishin, Z.S. *et al.* Calibration of an Inertial Measurement Unit. *Int Appl Mech* **53,** 228–236 (2017). https://doi.org/10.1007/s10778-017-0808-4
* T. Qin, P. Li and S. Shen, "VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator," in IEEE Transactions on Robotics, vol. 34, no. 4, pp. 1004-1020, Aug. 2018, doi: 10.1109/TRO.2018.2853729.
* C. Forster, S. Lynen, L. Kneip and D. Scaramuzza, "Collaborative monocular SLAM with multiple Micro Aerial Vehicles," 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, 2013, pp. 3962-3970, doi: 10.1109/IROS.2013.6696923.
* 任伟建,高强,康朝海,霍凤财,张志强.移动机器人同步定位与建图技术综述[J].计算机测量与控制,2022,30(02):1-10+37.DOI:10.16526/j.cnki.11-4762/tp.2022.02.001.



> 20+
>
> ROS, PX4, 等也要有